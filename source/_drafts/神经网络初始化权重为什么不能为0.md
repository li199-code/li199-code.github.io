---
title: 神经网络初始化权重为什么不能为0
date: 2023-03-28 15:42:06
tags: deep-learning
categories: 动手pytorch
---
原来的困惑，权重是根据梯度大小来更新的，初始权重相同怎么会影响梯度更新呢？网上查阅答案，都说是什么损失函数根据权重大小进行分配，看的更是云里雾里。

自己想了一下，明白了。假如一个全连接网络，初始权重都是1，那么每个神经元的输出就都是相同的了。计算梯度时，梯度的每一项其实都是各层输出组合计算合成的，如果输出都相同，那么梯度也相同，那么无论更新多少次梯度，权重的相对大小都没有发生变换，等价于一个神经元。所以，权重不能初始化为一个常数。
